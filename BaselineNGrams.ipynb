{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "import re, os\n",
    "from nltk.tokenize import WhitespaceTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's read in a sample data file to see what we're dealing with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/416_TRANSCRIPT.csv\", delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_time</th>\n",
       "      <th>stop_time</th>\n",
       "      <th>speaker</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.400</td>\n",
       "      <td>14.330</td>\n",
       "      <td>Participant</td>\n",
       "      <td>&lt;sync&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28.905</td>\n",
       "      <td>50.445</td>\n",
       "      <td>Ellie</td>\n",
       "      <td>IntroV4Confirmation (hi i'm ellie thanks for c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50.720</td>\n",
       "      <td>51.150</td>\n",
       "      <td>Participant</td>\n",
       "      <td>sure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51.721</td>\n",
       "      <td>52.181</td>\n",
       "      <td>Ellie</td>\n",
       "      <td>okay_confirm (okay)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>53.239</td>\n",
       "      <td>55.509</td>\n",
       "      <td>Ellie</td>\n",
       "      <td>how_doingV (so how are you doing today)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>55.630</td>\n",
       "      <td>56.780</td>\n",
       "      <td>Participant</td>\n",
       "      <td>i'm doing good how are you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>57.980</td>\n",
       "      <td>59.490</td>\n",
       "      <td>Ellie</td>\n",
       "      <td>great_thanks (i'm great thanks)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>60.634</td>\n",
       "      <td>61.954</td>\n",
       "      <td>Ellie</td>\n",
       "      <td>where_originally (where are you from originally)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>62.670</td>\n",
       "      <td>63.320</td>\n",
       "      <td>Participant</td>\n",
       "      <td>chicago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>64.177</td>\n",
       "      <td>64.767</td>\n",
       "      <td>Ellie</td>\n",
       "      <td>really (really)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   start_time  stop_time      speaker  \\\n",
       "0      13.400     14.330  Participant   \n",
       "1      28.905     50.445        Ellie   \n",
       "2      50.720     51.150  Participant   \n",
       "3      51.721     52.181        Ellie   \n",
       "4      53.239     55.509        Ellie   \n",
       "5      55.630     56.780  Participant   \n",
       "6      57.980     59.490        Ellie   \n",
       "7      60.634     61.954        Ellie   \n",
       "8      62.670     63.320  Participant   \n",
       "9      64.177     64.767        Ellie   \n",
       "\n",
       "                                               value  \n",
       "0                                             <sync>  \n",
       "1  IntroV4Confirmation (hi i'm ellie thanks for c...  \n",
       "2                                               sure  \n",
       "3                                okay_confirm (okay)  \n",
       "4            how_doingV (so how are you doing today)  \n",
       "5                         i'm doing good how are you  \n",
       "6                    great_thanks (i'm great thanks)  \n",
       "7   where_originally (where are you from originally)  \n",
       "8                                            chicago  \n",
       "9                                    really (really)  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, this is a transcribed counseling conversation. Let's first join together all strings of consecutive messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_rows = []\n",
    "for i in range(1, len(df)):\n",
    "    # check for consecutive rows with same speaker\n",
    "    if df.loc[i, \"speaker\"] == df.loc[i - 1, \"speaker\"]:\n",
    "        df.loc[i, \"value\"] = str(df.loc[i - 1, \"value\"]) + \" \" + str(df.loc[i, \"value\"])\n",
    "        drop_rows.append(i - 1)\n",
    "df.drop(drop_rows, inplace=True)\n",
    "df = df[df.speaker == 'Participant'][\"value\"].apply(lambda x: re.sub(\"<.*>\", \"\", x))\n",
    "df = df[df != \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2                                                  sure\n",
       "5                            i'm doing good how are you\n",
       "8                                               chicago\n",
       "10                                                 yeah\n",
       "12                          about twenty five years ago\n",
       "14                               yeah it's been a while\n",
       "16             actually i haven't been back  i like l_a\n",
       "18                                           i like l_a\n",
       "20    mm it's a big city so it's kinda similar but t...\n",
       "23                                 family i was a child\n",
       "25             it took a little adjustment but not hard\n",
       "30    um the weather um i can't think of anything ri...\n",
       "33                                             traffic \n",
       "35    not really but i've traveled  traveled a littl...\n",
       "37    seeing new places different people the way the...\n",
       "41        or the middle of last year that was very nice\n",
       "46    um it's a good question i'm not really sure uh...\n",
       "48    i can't think of anything right off the bat wh...\n",
       "50                                            astronomy\n",
       "52                                          yeah it was\n",
       "Name: value, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've now extracted everything that the user has said. We can apply this process to all of the conversations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_conversation(df):\n",
    "    drop_rows = []\n",
    "    for i in range(1, len(df)):\n",
    "        # check for consecutive rows with same speaker\n",
    "        if df.loc[i, \"speaker\"] == df.loc[i - 1, \"speaker\"]:\n",
    "            df.loc[i, \"value\"] = str(df.loc[i - 1, \"value\"]) + \" \" + str(df.loc[i, \"value\"])\n",
    "            drop_rows.append(i - 1)\n",
    "    df = df.drop(drop_rows)\n",
    "    df = df[df.speaker == 'Participant'][\"value\"].apply(lambda x: re.sub(\"<.*>\", \"\", x))\n",
    "    df = df[df != \"\"]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "318_TRANSCRIPT.csv\n",
      "376_TRANSCRIPT.csv\n",
      "480_TRANSCRIPT.csv\n",
      "403_TRANSCRIPT.csv\n",
      "375_TRANSCRIPT.csv\n",
      "413_TRANSCRIPT.csv\n",
      "462_TRANSCRIPT.csv\n",
      "348_TRANSCRIPT.csv\n",
      "475_TRANSCRIPT.csv\n",
      "314_TRANSCRIPT.csv\n",
      "463_TRANSCRIPT.csv\n",
      "336_TRANSCRIPT.csv\n",
      "324_TRANSCRIPT.csv\n",
      "397_TRANSCRIPT.csv\n",
      "361_TRANSCRIPT.csv\n",
      "433_TRANSCRIPT.csv\n",
      "382_TRANSCRIPT.csv\n",
      "365_TRANSCRIPT.csv\n",
      "357_TRANSCRIPT.csv\n",
      "329_TRANSCRIPT.csv\n",
      "392_TRANSCRIPT.csv\n",
      "399_TRANSCRIPT.csv\n",
      "332_TRANSCRIPT.csv\n",
      "328_TRANSCRIPT.csv\n",
      "325_TRANSCRIPT.csv\n",
      "311_TRANSCRIPT.csv\n",
      "369_TRANSCRIPT.csv\n",
      "308_TRANSCRIPT.csv\n",
      "470_TRANSCRIPT.csv\n",
      "315_TRANSCRIPT.csv\n",
      "387_TRANSCRIPT.csv\n",
      "373_TRANSCRIPT.csv\n",
      "428_TRANSCRIPT.csv\n",
      "461_TRANSCRIPT.csv\n",
      "456_TRANSCRIPT.csv\n",
      "409_TRANSCRIPT.csv\n",
      "418_TRANSCRIPT.csv\n",
      "386_TRANSCRIPT.csv\n",
      "395_TRANSCRIPT.csv\n",
      "309_TRANSCRIPT.csv\n",
      "372_TRANSCRIPT.csv\n",
      "371_TRANSCRIPT.csv\n",
      "422_TRANSCRIPT.csv\n",
      "312_TRANSCRIPT.csv\n",
      "434_TRANSCRIPT.csv\n",
      "458_TRANSCRIPT.csv\n",
      "321_TRANSCRIPT.csv\n",
      "489_TRANSCRIPT.csv\n",
      "471_TRANSCRIPT.csv\n",
      "431_TRANSCRIPT.csv\n",
      "368_TRANSCRIPT.csv\n",
      "307_TRANSCRIPT.csv\n",
      "383_TRANSCRIPT.csv\n",
      "340_TRANSCRIPT.csv\n",
      "302_TRANSCRIPT.csv\n",
      "345_TRANSCRIPT.csv\n",
      "459_TRANSCRIPT.csv\n",
      "452_TRANSCRIPT.csv\n",
      "401_TRANSCRIPT.csv\n",
      "334_TRANSCRIPT.csv\n",
      "417_TRANSCRIPT.csv\n",
      "450_TRANSCRIPT.csv\n",
      "479_TRANSCRIPT.csv\n",
      "374_TRANSCRIPT.csv\n",
      "405_TRANSCRIPT.csv\n",
      "385_TRANSCRIPT.csv\n",
      "429_TRANSCRIPT.csv\n",
      "446_TRANSCRIPT.csv\n",
      "442_TRANSCRIPT.csv\n",
      "381_TRANSCRIPT.csv\n",
      "457_TRANSCRIPT.csv\n",
      "355_TRANSCRIPT.csv\n",
      "344_TRANSCRIPT.csv\n",
      "412_TRANSCRIPT.csv\n",
      "473_TRANSCRIPT.csv\n",
      "490_TRANSCRIPT.csv\n",
      "449_TRANSCRIPT.csv\n",
      "320_TRANSCRIPT.csv\n",
      "362_TRANSCRIPT.csv\n",
      "347_TRANSCRIPT.csv\n",
      "426_TRANSCRIPT.csv\n",
      "337_TRANSCRIPT.csv\n",
      "339_TRANSCRIPT.csv\n",
      "366_TRANSCRIPT.csv\n",
      "424_TRANSCRIPT.csv\n",
      "393_TRANSCRIPT.csv\n",
      "430_TRANSCRIPT.csv\n",
      "333_TRANSCRIPT.csv\n",
      "316_TRANSCRIPT.csv\n",
      "330_TRANSCRIPT.csv\n",
      "313_TRANSCRIPT.csv\n",
      "335_TRANSCRIPT.csv\n",
      "487_TRANSCRIPT.csv\n",
      "388_TRANSCRIPT.csv\n",
      "364_TRANSCRIPT.csv\n",
      "352_TRANSCRIPT.csv\n",
      "380_TRANSCRIPT.csv\n",
      "389_TRANSCRIPT.csv\n",
      "447_TRANSCRIPT.csv\n",
      "427_TRANSCRIPT.csv\n",
      "300_TRANSCRIPT.csv\n",
      "411_TRANSCRIPT.csv\n",
      "441_TRANSCRIPT.csv\n",
      "303_TRANSCRIPT.csv\n",
      "319_TRANSCRIPT.csv\n",
      "484_TRANSCRIPT.csv\n",
      "414_TRANSCRIPT.csv\n",
      "407_TRANSCRIPT.csv\n",
      "467_TRANSCRIPT.csv\n",
      "455_TRANSCRIPT.csv\n",
      "354_TRANSCRIPT.csv\n",
      "466_TRANSCRIPT.csv\n",
      "396_TRANSCRIPT.csv\n",
      "310_TRANSCRIPT.csv\n",
      "360_TRANSCRIPT.csv\n",
      "488_TRANSCRIPT.csv\n",
      "465_TRANSCRIPT.csv\n",
      "338_TRANSCRIPT.csv\n",
      "378_TRANSCRIPT.csv\n",
      "485_TRANSCRIPT.csv\n",
      "301_TRANSCRIPT.csv\n",
      "451_TRANSCRIPT.csv\n",
      "448_TRANSCRIPT.csv\n",
      "341_TRANSCRIPT.csv\n",
      "469_TRANSCRIPT.csv\n",
      "406_TRANSCRIPT.csv\n",
      "358_TRANSCRIPT.csv\n",
      "408_TRANSCRIPT.csv\n",
      "436_TRANSCRIPT.csv\n",
      "370_TRANSCRIPT.csv\n",
      "304_TRANSCRIPT.csv\n",
      "359_TRANSCRIPT.csv\n",
      "384_TRANSCRIPT.csv\n",
      "400_TRANSCRIPT.csv\n",
      "435_TRANSCRIPT.csv\n",
      "416_TRANSCRIPT.csv\n",
      "377_TRANSCRIPT.csv\n",
      "491_TRANSCRIPT.csv\n",
      "323_TRANSCRIPT.csv\n",
      "476_TRANSCRIPT.csv\n",
      "415_TRANSCRIPT.csv\n",
      "468_TRANSCRIPT.csv\n",
      "420_TRANSCRIPT.csv\n",
      "478_TRANSCRIPT.csv\n",
      "474_TRANSCRIPT.csv\n",
      "421_TRANSCRIPT.csv\n",
      "317_TRANSCRIPT.csv\n",
      "477_TRANSCRIPT.csv\n",
      "464_TRANSCRIPT.csv\n",
      "351_TRANSCRIPT.csv\n",
      "423_TRANSCRIPT.csv\n",
      "453_TRANSCRIPT.csv\n",
      "349_TRANSCRIPT.csv\n",
      "437_TRANSCRIPT.csv\n",
      "439_TRANSCRIPT.csv\n",
      "402_TRANSCRIPT.csv\n",
      "379_TRANSCRIPT.csv\n",
      "486_TRANSCRIPT.csv\n",
      "331_TRANSCRIPT.csv\n",
      "444_TRANSCRIPT.csv\n",
      "353_TRANSCRIPT.csv\n",
      "404_TRANSCRIPT.csv\n",
      "363_TRANSCRIPT.csv\n",
      "326_TRANSCRIPT.csv\n",
      "306_TRANSCRIPT.csv\n",
      "481_TRANSCRIPT.csv\n",
      "472_TRANSCRIPT.csv\n",
      "322_TRANSCRIPT.csv\n",
      "445_TRANSCRIPT.csv\n",
      "346_TRANSCRIPT.csv\n",
      "482_TRANSCRIPT.csv\n",
      "356_TRANSCRIPT.csv\n",
      "367_TRANSCRIPT.csv\n",
      "390_TRANSCRIPT.csv\n",
      "410_TRANSCRIPT.csv\n",
      "419_TRANSCRIPT.csv\n",
      "454_TRANSCRIPT.csv\n",
      "327_TRANSCRIPT.csv\n",
      "425_TRANSCRIPT.csv\n",
      "391_TRANSCRIPT.csv\n",
      "443_TRANSCRIPT.csv\n",
      "305_TRANSCRIPT.csv\n",
      "438_TRANSCRIPT.csv\n",
      "492_TRANSCRIPT.csv\n",
      "483_TRANSCRIPT.csv\n",
      "350_TRANSCRIPT.csv\n",
      "440_TRANSCRIPT.csv\n",
      "343_TRANSCRIPT.csv\n",
      "432_TRANSCRIPT.csv\n"
     ]
    }
   ],
   "source": [
    "convs = []\n",
    "for file in os.listdir(\"../data\"):\n",
    "    if file.endswith(\".csv\"):\n",
    "        print(file)\n",
    "        df = pd.read_csv(\"../data/\" + file, delimiter=\"\\t\")\n",
    "        convs.append(parse_conversation(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "convs_full = pd.concat(convs).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tk = WhitespaceTokenizer()\n",
    "tokenized = []\n",
    "for conv in convs_full:\n",
    "    try:\n",
    "        tokenized.append([\"<s>\"] + tk.tokenize(conv) + [\"</s>\"])\n",
    "    except:\n",
    "        print(conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets all of the ngrams and their counts for the given dataset\n",
    "def get_ngram_counts(tweets, n):\n",
    "    counts = {}\n",
    "    for tweet in tweets:\n",
    "        for i in range(len(tweet) - n + 1):\n",
    "            ngram = \" \".join(tweet[i:i+n])\n",
    "            counts[ngram] = counts.get(ngram, 0) + 1\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = get_ngram_counts(tokenized, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams_df = pd.DataFrame(counts.items(), columns=[\"ngram\", \"count\"])\n",
    "\n",
    "start_ngrams = ngrams_df[ngrams_df.ngram.str.startswith(\"<s>\")].copy()\n",
    "start_ngrams[\"count\"] /= start_ngrams[\"count\"].sum()\n",
    "\n",
    "other_ngrams = ngrams_df[~ngrams_df.ngram.str.startswith(\"<s>\")].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_sentence(start_ngrams, other_ngrams, n, gen_count):\n",
    "    for i in range(gen_count):\n",
    "        start = np.random.choice(start_ngrams[\"ngram\"], p=start_ngrams[\"count\"]).split(\" \")\n",
    "        sentence = start\n",
    "\n",
    "        while sentence[-1] != \"</s>\":\n",
    "            curr_choices = other_ngrams[other_ngrams.ngram.str.startswith(\" \".join(sentence[-n+1:]) + \" \")].copy()\n",
    "            curr_choices[\"count\"] /= curr_choices[\"count\"].sum()\n",
    "            curr = np.random.choice(curr_choices[\"ngram\"], p=curr_choices[\"count\"]).split(\" \")\n",
    "            sentence.append(curr[-1])\n",
    "\n",
    "        print(\" \".join(sentence[1:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uh i would let me see uh well um i'm trying to get into a uh you might wanna say a a altercation with the rednecks down there because as as you know everything in the world and seeing all the colors in the ocean\n",
      "philosophy i have my best friend and i drove my car too fast and that that i'm trustworthy\n",
      "uh business\n",
      "oh yeah you can always fix what you did in your past otherwise you wouldn't need to get over that so after spending one year in in my life uh my daughter my son my daughter's a great source of pride and um um that's mm that's about it\n",
      "um in that moment\n",
      "it's spread out a lot uh not trusting uh suspiciousness of other people i mean probably as somebody who oddly enough somebody who is laid back and chill\n",
      "i'm doing good\n",
      "when i'm annoyed\n",
      "i was i was getting in trouble and i was kind of a difficult decision\n",
      "uh um probably the one of my weaker points i would say a counselor to some people you know some of them not strong enough and so i found when i got to get together and do things\n"
     ]
    }
   ],
   "source": [
    "gen_sentence(start_ngrams, other_ngrams, 4, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
